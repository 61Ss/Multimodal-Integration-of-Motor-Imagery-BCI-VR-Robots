#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾ç¡®äº’ä¿¡æ¯åˆ†æ - ä½¿ç”¨çœŸå®çš„ä¿¡æ¯è®ºäº’ä¿¡æ¯è®¡ç®—

âš ï¸ è­¦å‘Šï¼šæ­¤ç‰ˆæœ¬é€Ÿåº¦ææ…¢ä½†ç»“æœç²¾ç¡®ï¼Œé€‚åˆå°æ ·æœ¬æˆ–æœ€ç»ˆéªŒè¯
"""

import numpy as np
import pandas as pd
from scipy.signal import butter, sosfilt
from sklearn.feature_selection import mutual_info_regression
from sklearn.decomposition import IncrementalPCA
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors
import time
import os
import sys
from functools import partial
from multiprocessing import Pool

# è§£å†³Windowsä¸ŠKMeansçš„å†…å­˜æ³„æ¼è­¦å‘Š
os.environ['OMP_NUM_THREADS'] = '2'

# å¯¼å…¥ç°æœ‰çš„æ•°æ®åŠ è½½å‡½æ•°
from visualize_eeg_psd import load_eeg_data

class ExactMutualInformationAnalyzer:
    """
    ç²¾ç¡®EEGäº’ä¿¡æ¯åˆ†æå™¨ - ä½¿ç”¨çœŸå®çš„ä¿¡æ¯è®ºäº’ä¿¡æ¯
    
    é€‚ç”¨äºï¼š
    1. å°æ ·æœ¬ç²¾ç¡®åˆ†æ (â‰¤20 trials)
    2. æ–¹æ³•éªŒè¯
    3. æœ€ç»ˆç»“æœç¡®è®¤
    """
    
    def __init__(self, subject_id='aw', random_state=42, verbose=True, 
                 n_jobs=4, mi_neighbors=3):
        """
        åˆå§‹åŒ–ç²¾ç¡®åˆ†æå™¨
        
        Parameters:
        -----------
        n_jobs : int
            å¹¶è¡Œè®¡ç®—çš„è¿›ç¨‹æ•°
        mi_neighbors : int
            äº’ä¿¡æ¯è®¡ç®—ä¸­çš„é‚»å±…æ•°ï¼ˆå½±å“ç²¾åº¦å’Œé€Ÿåº¦ï¼‰
        """
        self.subject_id = subject_id
        self.random_state = random_state
        self.verbose = verbose
        self.n_jobs = n_jobs
        self.mi_neighbors = mi_neighbors
        
        # é¢‘æ®µå®šä¹‰
        self.bands = {
            'alpha': (7, 13),
            'beta': (14, 30), 
            'gamma': (30, 100)
        }
        
        # PCAå’Œèšç±»å‚æ•°
        self.pca_components = 20
        self.kmeans_clusters = 2
        self.n_neighbors = 5
        self.density_percentile = 85
    
    def calculate_exact_mutual_information_matrix(self, data):
        """
        è®¡ç®—ç²¾ç¡®çš„äº’ä¿¡æ¯çŸ©é˜µ
        
        ä½¿ç”¨sklearnçš„mutual_info_regressionè®¡ç®—çœŸå®çš„äº’ä¿¡æ¯
        """
        num_channels = data.shape[1]
        mi_matrix = np.zeros((num_channels, num_channels))
        
        if self.verbose:
            print(f"    è®¡ç®—{num_channels}Ã—{num_channels}ç²¾ç¡®äº’ä¿¡æ¯çŸ©é˜µ...")
        
        # è®¡ç®—æ‰€æœ‰é€šé“å¯¹çš„äº’ä¿¡æ¯
        channel_pairs = [(i, j) for i in range(num_channels) for j in range(i + 1, num_channels)]
        total_pairs = len(channel_pairs)
        
        if self.verbose:
            print(f"    æ€»å…±{total_pairs}ä¸ªé€šé“å¯¹éœ€è¦è®¡ç®—")
        
        if self.n_jobs > 1:
            # å¹¶è¡Œè®¡ç®—
            mi_func = partial(self._compute_exact_mi_pair, data=data)
            with Pool(self.n_jobs) as pool:
                mi_values = pool.map(mi_func, channel_pairs)
        else:
            # ä¸²è¡Œè®¡ç®—
            mi_values = []
            for idx, (i, j) in enumerate(channel_pairs):
                if self.verbose and idx % max(1, total_pairs // 10) == 0:
                    print(f"      è¿›åº¦: {idx}/{total_pairs} ({100*idx/total_pairs:.0f}%)")
                
                mi_value = mutual_info_regression(
                    data[:, i].reshape(-1, 1), 
                    data[:, j],
                    discrete_features=False,
                    n_neighbors=self.mi_neighbors,
                    random_state=self.random_state
                )[0]
                mi_values.append(mi_value)
        
        # å¡«å……å¯¹ç§°çŸ©é˜µ
        for (i, j), mi_value in zip(channel_pairs, mi_values):
            mi_matrix[i, j] = mi_value
            mi_matrix[j, i] = mi_value
        
        # å¯¹è§’çº¿è®¾ä¸º0ï¼ˆè‡ªå·±ä¸è‡ªå·±çš„äº’ä¿¡æ¯ä¸è€ƒè™‘ï¼‰
        np.fill_diagonal(mi_matrix, 0)
        
        return mi_matrix
    
    def _compute_exact_mi_pair(self, channel_pair, data):
        """è®¡ç®—å•ä¸ªé€šé“å¯¹çš„ç²¾ç¡®äº’ä¿¡æ¯ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
        i, j = channel_pair
        mi_value = mutual_info_regression(
            data[:, i].reshape(-1, 1), 
            data[:, j],
            discrete_features=False,
            n_neighbors=self.mi_neighbors,
            random_state=self.random_state
        )[0]
        return mi_value
    
    def apply_bandpass_filter(self, data, band, fs):
        """åº”ç”¨å¸¦é€šæ»¤æ³¢"""
        fmin, fmax = band
        nyquist = fs / 2
        low = fmin / nyquist
        high = min(fmax / nyquist, 0.99)
        
        # ä½¿ç”¨SOSæ ¼å¼æ»¤æ³¢å™¨
        sos = butter(2, [low, high], btype='band', output='sos')
        
        filtered_data = np.zeros_like(data)
        for ch in range(data.shape[1]):
            filtered_data[:, ch] = sosfilt(sos, data[:, ch])
        
        return filtered_data
    
    def analyze_single_trial_exact(self, trial_idx):
        """ç²¾ç¡®åˆ†æå•ä¸ªtrial"""
        if self.verbose:
            print(f"\nåˆ†æTrial {trial_idx}...")
        
        trial_data = self.trials[trial_idx]
        
        # å­˜å‚¨å„é¢‘æ®µçš„äº’ä¿¡æ¯çŸ©é˜µ
        band_mi_matrices = {}
        
        for band_name, band_range in self.bands.items():
            if self.verbose:
                print(f"  å¤„ç†{band_name}é¢‘æ®µ ({band_range[0]}-{band_range[1]} Hz)...")
            
            # æ»¤æ³¢
            start_time = time.time()
            filtered_data = self.apply_bandpass_filter(trial_data, band_range, self.fs)
            filter_time = time.time() - start_time
            
            if self.verbose:
                print(f"    æ»¤æ³¢è€—æ—¶: {filter_time:.2f}ç§’")
            
            # è®¡ç®—ç²¾ç¡®äº’ä¿¡æ¯çŸ©é˜µ
            start_time = time.time()
            mi_matrix = self.calculate_exact_mutual_information_matrix(filtered_data)
            mi_time = time.time() - start_time
            
            if self.verbose:
                print(f"    äº’ä¿¡æ¯è®¡ç®—è€—æ—¶: {mi_time:.2f}ç§’")
                print(f"    äº’ä¿¡æ¯çŸ©é˜µç»Ÿè®¡: å‡å€¼={np.mean(mi_matrix):.4f}, æœ€å¤§å€¼={np.max(mi_matrix):.4f}")
            
            band_mi_matrices[band_name] = mi_matrix
        
        return band_mi_matrices
    
    def load_and_preprocess_data(self):
        """åŠ è½½å¹¶é¢„å¤„ç†EEGæ•°æ®"""
        if self.verbose:
            print("===== åŠ è½½æ•°æ® =====")
        
        trials, fs, ch_names, ch_pos, trial_labels, regions = load_eeg_data(self.subject_id)
        
        self.trials = trials
        self.fs = fs
        self.ch_names = ch_names
        self.ch_pos = ch_pos
        self.trial_labels = trial_labels
        self.regions = regions
        
        if self.verbose:
            print(f"æ•°æ®å½¢çŠ¶: {trials.shape}")
            print(f"ä½¿ç”¨ç²¾ç¡®äº’ä¿¡æ¯è®¡ç®—ï¼ˆsklearn.mutual_info_regressionï¼‰")
            print(f"å¹¶è¡Œè¿›ç¨‹æ•°: {self.n_jobs}")
            print(f"äº’ä¿¡æ¯é‚»å±…æ•°: {self.mi_neighbors}")
        
        return trials
    
    def calculate_density_labels_fast(self):
        """å¿«é€Ÿè®¡ç®—å¯†åº¦æ ‡ç­¾ï¼ˆä¸ultra_fastç‰ˆæœ¬ç›¸åŒï¼‰"""
        if self.verbose:
            print("===== è®¡ç®—å¯†åº¦æ ‡ç­¾ =====")
        
        # ä½¿ç”¨é‡‡æ ·ç‰ˆæœ¬å¿«é€Ÿè®¡ç®—å¯†åº¦æ ‡ç­¾
        num_trials, num_timepoints, num_channels = self.trials.shape
        
        sample_step = max(1, num_timepoints // 50)
        sampled_trials = self.trials[:, ::sample_step, ::2]
        flattened_trials = sampled_trials.reshape(num_trials, -1)
        
        # å¿«é€ŸPCA
        pca = IncrementalPCA(n_components=self.pca_components, batch_size=min(50, num_trials))
        
        batch_size = min(50, num_trials)
        for i in range(0, num_trials, batch_size):
            batch = flattened_trials[i:i + batch_size]
            pca.partial_fit(batch)
        
        pca_results = pca.transform(flattened_trials)
        
        # K-meansèšç±»
        kmeans = KMeans(n_clusters=self.kmeans_clusters, random_state=self.random_state, n_init=3)
        cluster_labels = kmeans.fit_predict(pca_results)
        
        # å¯†åº¦è®¡ç®—
        nn = NearestNeighbors(n_neighbors=min(self.n_neighbors, num_trials//2))
        nn.fit(pca_results)
        distances, _ = nn.kneighbors(pca_results)
        density = np.mean(distances, axis=1)
        
        # å¯†åº¦æ ‡ç­¾åˆ†é…
        clusters = np.unique(cluster_labels)
        density_labels = [''] * num_trials
        
        for cluster in clusters:
            cluster_mask = cluster_labels == cluster
            threshold = np.percentile(density[cluster_mask], self.density_percentile)
            
            for i in range(num_trials):
                if cluster_mask[i]:
                    density_labels[i] = 'high' if density[i] <= threshold else 'low'
        
        density_labels = np.array(density_labels, dtype='U10')
        self.density_labels = density_labels
        self.cluster_labels = cluster_labels
        
        if self.verbose:
            high_count = np.sum(density_labels == 'high')
            low_count = np.sum(density_labels == 'low')
            print(f"å¯†åº¦æ ‡ç­¾åˆ†å¸ƒ: High={high_count}, Low={low_count}")
        
        return density_labels
    
    def calculate_average_mi_and_rank_channels(self, band_mi_matrices):
        """è®¡ç®—å¹³å‡äº’ä¿¡æ¯å¹¶æ’åºé€šé“"""
        # è®¡ç®—ä¸‰ä¸ªé¢‘æ®µçš„å¹³å‡
        alpha_mi = band_mi_matrices['alpha']
        beta_mi = band_mi_matrices['beta']
        gamma_mi = band_mi_matrices['gamma']
        
        avg_mi_matrix = (alpha_mi + beta_mi + gamma_mi) / 3
        
        # è®¡ç®—æ¯ä¸ªé€šé“çš„è¿æ¥å¼ºåº¦
        channel_connectivity = np.sum(avg_mi_matrix, axis=1)
        
        # æ’åºè·å–å‰4ä¸ªé€šé“
        top_channels_indices = np.argsort(channel_connectivity)[-4:][::-1]
        top_channels_scores = channel_connectivity[top_channels_indices]
        top_channels_names = [self.ch_names[i] for i in top_channels_indices]
        
        return avg_mi_matrix, top_channels_indices, top_channels_scores, top_channels_names
    
    def run_exact_analysis(self, max_trials=None):
        """è¿è¡Œç²¾ç¡®åˆ†ææµç¨‹"""
        if self.verbose:
            print("===== ç²¾ç¡®EEGäº’ä¿¡æ¯åˆ†æ =====")
            print("ğŸ¯ ä½¿ç”¨çœŸå®çš„ä¿¡æ¯è®ºäº’ä¿¡æ¯è®¡ç®—")
            print("âš ï¸  è­¦å‘Šï¼šé€Ÿåº¦ææ…¢ï¼Œå»ºè®®åªç”¨äºå°æ ·æœ¬")
        
        # åŠ è½½æ•°æ®
        self.load_and_preprocess_data()
        
        # è®¡ç®—å¯†åº¦æ ‡ç­¾
        self.calculate_density_labels_fast()
        
        # é™åˆ¶trialsæ•°é‡
        if max_trials is not None and max_trials < self.trials.shape[0]:
            if self.verbose:
                print(f"é™åˆ¶åˆ†æï¼šåªå¤„ç†å‰ {max_trials} ä¸ªtrials")
            self.trials = self.trials[:max_trials]
            self.trial_labels = self.trial_labels[:max_trials]
            self.density_labels = self.density_labels[:max_trials]
            self.cluster_labels = self.cluster_labels[:max_trials]
        
        # åˆ†ææ‰€æœ‰trials
        num_trials = self.trials.shape[0]
        results = []
        
        overall_start = time.time()
        
        for trial_idx in range(num_trials):
            trial_start = time.time()
            
            # åˆ†æå½“å‰trial
            band_mi_matrices = self.analyze_single_trial_exact(trial_idx)
            avg_mi_matrix, top_indices, top_scores, top_names = self.calculate_average_mi_and_rank_channels(band_mi_matrices)
            
            # ä¿å­˜ç»“æœ
            trial_result = {
                'trial_idx': trial_idx,
                'original_label': self.trial_labels[trial_idx],
                'density_label': self.density_labels[trial_idx],
                'cluster_label': self.cluster_labels[trial_idx],
                'top_4_channels': top_names,
                'top_4_indices': top_indices,
                'top_4_scores': top_scores,
            }
            
            results.append(trial_result)
            
            trial_time = time.time() - trial_start
            remaining_trials = num_trials - trial_idx - 1
            estimated_remaining = trial_time * remaining_trials
            
            if self.verbose:
                print(f"\nTrial {trial_idx} å®Œæˆ (è€—æ—¶: {trial_time:.1f}ç§’)")
                print(f"é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining/60:.1f}åˆ†é’Ÿ")
        
        total_time = time.time() - overall_start
        
        if self.verbose:
            print(f"\nğŸ‰ ç²¾ç¡®åˆ†æå®Œæˆ!")
            print(f"æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
            print(f"å¹³å‡æ¯trial: {total_time/num_trials:.1f}ç§’")
        
        # ä¿å­˜ç»“æœ
        suffix = f'_first{max_trials}' if max_trials is not None else ''
        output_csv = f'exact_mi_results_{self.subject_id}{suffix}.csv'
        
        data_rows = []
        for result in results:
            row = {
                'trial_idx': result['trial_idx'],
                'original_label': result['original_label'],
                'density_label': result['density_label'],
                'cluster_label': result['cluster_label'],
                'top_channel_1': result['top_4_channels'][0],
                'top_channel_1_score': result['top_4_scores'][0],
                'top_channel_2': result['top_4_channels'][1],
                'top_channel_2_score': result['top_4_scores'][1],
                'top_channel_3': result['top_4_channels'][2],
                'top_channel_3_score': result['top_4_scores'][2],
                'top_channel_4': result['top_4_channels'][3],
                'top_channel_4_score': result['top_4_scores'][3],
            }
            data_rows.append(row)
        
        df = pd.DataFrame(data_rows)
        df.to_csv(output_csv, index=False, encoding='utf-8-sig')
        
        if self.verbose:
            print(f"ç»“æœå·²ä¿å­˜è‡³: {output_csv}")
        
        return results, df

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    max_trials = 3  # é»˜è®¤åªåˆ†æ3ä¸ªtrials
    
    for arg in sys.argv:
        if arg.startswith('--trials='):
            try:
                max_trials = int(arg.split('=')[1])
            except ValueError:
                print("âš ï¸ æ— æ•ˆçš„trialså‚æ•°")
    
    if '--help' in sys.argv:
        print("ç²¾ç¡®äº’ä¿¡æ¯åˆ†æ - ä½¿ç”¨çœŸå®çš„ä¿¡æ¯è®ºäº’ä¿¡æ¯")
        print("ç”¨æ³•: python exact_mutual_information.py [--trials=N]")
        print("å‚æ•°:")
        print("  --trials=N  : åˆ†æçš„trialsæ•°é‡ï¼ˆé»˜è®¤3ï¼Œå»ºè®®â‰¤10ï¼‰")
        print("  --help      : æ˜¾ç¤ºå¸®åŠ©")
        print("\nâš ï¸ è­¦å‘Šï¼šæ¯ä¸ªtrialéœ€è¦çº¦60ç§’ï¼Œè¯·è°¨æ…è®¾ç½®trialsæ•°é‡")
        return
    
    # æ—¶é—´ä¼°ç®—è­¦å‘Š
    estimated_time = max_trials * 60  # æ¯ä¸ªtrialçº¦60ç§’
    print(f"âš ï¸ æ—¶é—´è­¦å‘Šï¼šé¢„è®¡éœ€è¦ {estimated_time/60:.1f} åˆ†é’Ÿå®Œæˆ {max_trials} ä¸ªtrials")
    print("å¦‚æœæ—¶é—´å¤ªé•¿ï¼Œè¯·ä½¿ç”¨ --trials=N å‡å°‘trialsæ•°é‡")
    
    response = input("\nç»§ç»­å—ï¼Ÿ (y/N): ")
    if response.lower() != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    # åˆ›å»ºç²¾ç¡®åˆ†æå™¨
    analyzer = ExactMutualInformationAnalyzer(
        subject_id='aw',
        random_state=42,
        verbose=True,
        n_jobs=4,  # å¹¶è¡Œè¿›ç¨‹æ•°
        mi_neighbors=3
    )
    
    # è¿è¡Œåˆ†æ
    start_time = time.time()
    results, df = analyzer.run_exact_analysis(max_trials=max_trials)
    total_time = time.time() - start_time
    
    print(f"\nğŸ‰ ç²¾ç¡®åˆ†æå®Œæˆ!")
    print(f"æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    print(f"æ¯trialå¹³å‡: {total_time/len(results):.1f}ç§’")

if __name__ == '__main__':
    main()