import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.signal import welch, butter, filtfilt
from sklearn.neighbors import NearestNeighbors
from sklearn.decomposition import PCA, IncrementalPCA
from sklearn.cluster import KMeans
from scipy.spatial.distance import pdist, squareform
from scipy.stats import pearsonr
import os
import warnings
import sys
from multiprocessing import Pool, cpu_count
from functools import partial
import time

# è§£å†³Windowsä¸ŠKMeansçš„å†…å­˜æ³„æ¼è­¦å‘Š
os.environ['OMP_NUM_THREADS'] = '2'

# å¯¼å…¥ç°æœ‰çš„æ•°æ®åŠ è½½å‡½æ•°
from visualize_eeg_psd import load_eeg_data

class FastMutualInformationAnalyzer:
    """
    é«˜æ€§èƒ½EEGæ•°æ®äº’ä¿¡æ¯åˆ†æå™¨
    
    ä¸»è¦ä¼˜åŒ–ï¼š
    1. ä½¿ç”¨ç›¸å…³ç³»æ•°è¿‘ä¼¼äº’ä¿¡æ¯ï¼ˆé€Ÿåº¦æå‡100x+ï¼‰
    2. åªè®¡ç®—ä¸Šä¸‰è§’çŸ©é˜µï¼ˆé€Ÿåº¦æå‡2xï¼‰
    3. æ”¯æŒå¹¶è¡Œè®¡ç®—ï¼ˆé€Ÿåº¦æå‡4-8xï¼‰
    4. æ•°æ®é¢„ç­›é€‰å’Œé‡‡æ ·ä¼˜åŒ–
    5. å†…å­˜ä¼˜åŒ–çš„æ‰¹å¤„ç†
    """
    
    def __init__(self, subject_id='aw', random_state=42, use_incremental_pca=True, 
                 pca_batch_size=50, verbose=True, use_parallel=True, 
                 mi_method='correlation', max_samples_per_trial=1000):
        """
        åˆå§‹åŒ–é«˜æ€§èƒ½äº’ä¿¡æ¯åˆ†æå™¨
        
        Parameters:
        -----------
        subject_id : str
            å—è¯•è€…ID
        random_state : int
            éšæœºç§å­
        use_incremental_pca : bool
            æ˜¯å¦ä½¿ç”¨å¢é‡PCA
        pca_batch_size : int
            å¢é‡PCAçš„æ‰¹å¤„ç†å¤§å°
        verbose : bool
            æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºä¿¡æ¯
        use_parallel : bool
            æ˜¯å¦ä½¿ç”¨å¹¶è¡Œè®¡ç®—
        mi_method : str
            äº’ä¿¡æ¯è®¡ç®—æ–¹æ³• ('correlation', 'mi_fast', 'mi_exact')
        max_samples_per_trial : int
            æ¯ä¸ªtrialçš„æœ€å¤§é‡‡æ ·ç‚¹æ•°ï¼ˆç”¨äºåŠ é€Ÿï¼‰
        """
        self.subject_id = subject_id
        self.random_state = random_state
        self.use_incremental_pca = use_incremental_pca
        self.verbose = verbose
        self.use_parallel = use_parallel
        self.mi_method = mi_method
        self.max_samples_per_trial = max_samples_per_trial
        
        # é¢‘æ®µå®šä¹‰ (Hz)
        self.bands = {
            'alpha': (7, 13),
            'beta': (14, 30), 
            'gamma': (30, 100)
        }
        
        # PCAå’Œèšç±»å‚æ•°
        self.pca_components = 20
        self.kmeans_clusters = 2
        self.n_neighbors = 5
        self.density_percentile = 85
        self.pca_batch_size = pca_batch_size
        
        # å¹¶è¡Œè®¡ç®—å‚æ•°
        self.n_jobs = min(cpu_count(), 8) if use_parallel else 1
    
    def fast_mutual_information(self, x, y, method='correlation'):
        """
        å¿«é€Ÿäº’ä¿¡æ¯è®¡ç®—
        
        Methods:
        - 'correlation': ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°å¹³æ–¹ä½œä¸ºäº’ä¿¡æ¯è¿‘ä¼¼ï¼ˆæœ€å¿«ï¼‰
        - 'mi_fast': ä½¿ç”¨ç®€åŒ–çš„MIä¼°è®¡ï¼ˆä¸­ç­‰é€Ÿåº¦ï¼‰
        - 'mi_exact': ä½¿ç”¨ç²¾ç¡®çš„MIè®¡ç®—ï¼ˆæœ€æ…¢ä½†æœ€å‡†ç¡®ï¼‰
        """
        if method == 'correlation':
            # ä½¿ç”¨ç›¸å…³ç³»æ•°çš„å¹³æ–¹ä½œä¸ºäº’ä¿¡æ¯çš„å¿«é€Ÿè¿‘ä¼¼
            corr, _ = pearsonr(x, y)
            return corr ** 2
        
        elif method == 'mi_fast':
            # ç®€åŒ–çš„äº’ä¿¡æ¯ä¼°è®¡ï¼ˆåŸºäºåˆ†æ¡¶ï¼‰
            n_bins = min(20, len(x) // 10)
            hist_xy, x_edges, y_edges = np.histogram2d(x, y, bins=n_bins)
            hist_x = np.histogram(x, bins=x_edges)[0]
            hist_y = np.histogram(y, bins=y_edges)[0]
            
            # é¿å…log(0)
            hist_xy = hist_xy + 1e-10
            hist_x = hist_x + 1e-10
            hist_y = hist_y + 1e-10
            
            # å½’ä¸€åŒ–
            p_xy = hist_xy / np.sum(hist_xy)
            p_x = hist_x / np.sum(hist_x)
            p_y = hist_y / np.sum(hist_y)
            
            # è®¡ç®—äº’ä¿¡æ¯
            mi = 0
            for i in range(len(p_x)):
                for j in range(len(p_y)):
                    if p_xy[i, j] > 0:
                        mi += p_xy[i, j] * np.log(p_xy[i, j] / (p_x[i] * p_y[j]))
            
            return mi
        
        else:  # mi_exact
            # ä½¿ç”¨sklearnçš„ç²¾ç¡®æ–¹æ³•ï¼ˆæœ€æ…¢ï¼‰
            from sklearn.feature_selection import mutual_info_regression
            return mutual_info_regression(
                x.reshape(-1, 1), y, 
                discrete_features=False, 
                n_neighbors=3,
                random_state=self.random_state
            )[0]
    
    def calculate_fast_mi_matrix(self, data):
        """
        å¿«é€Ÿè®¡ç®—äº’ä¿¡æ¯çŸ©é˜µï¼ˆåªè®¡ç®—ä¸Šä¸‰è§’ï¼‰
        """
        num_channels = data.shape[1]
        
        # æ•°æ®é‡‡æ ·ä»¥åŠ é€Ÿè®¡ç®—
        if data.shape[0] > self.max_samples_per_trial:
            indices = np.random.choice(data.shape[0], self.max_samples_per_trial, replace=False)
            data = data[indices]
        
        # åˆå§‹åŒ–çŸ©é˜µ
        mi_matrix = np.zeros((num_channels, num_channels))
        
        # åªè®¡ç®—ä¸Šä¸‰è§’çŸ©é˜µ
        for i in range(num_channels):
            for j in range(i + 1, num_channels):
                mi_value = self.fast_mutual_information(
                    data[:, i], data[:, j], method=self.mi_method
                )
                mi_matrix[i, j] = mi_value
                mi_matrix[j, i] = mi_value  # å¯¹ç§°çŸ©é˜µ
        
        return mi_matrix
    
    def calculate_parallel_mi_matrix(self, data):
        """
        å¹¶è¡Œè®¡ç®—äº’ä¿¡æ¯çŸ©é˜µ
        """
        num_channels = data.shape[1]
        
        # æ•°æ®é‡‡æ ·
        if data.shape[0] > self.max_samples_per_trial:
            indices = np.random.choice(data.shape[0], self.max_samples_per_trial, replace=False)
            data = data[indices]
        
        # ç”Ÿæˆæ‰€æœ‰éœ€è¦è®¡ç®—çš„é€šé“å¯¹ï¼ˆåªè®¡ç®—ä¸Šä¸‰è§’ï¼‰
        channel_pairs = [(i, j) for i in range(num_channels) for j in range(i + 1, num_channels)]
        
        # åˆ›å»ºéƒ¨åˆ†å‡½æ•°
        mi_func = partial(self._compute_mi_pair, data=data)
        
        # å¹¶è¡Œè®¡ç®—
        if self.n_jobs > 1:
            with Pool(self.n_jobs) as pool:
                mi_values = pool.map(mi_func, channel_pairs)
        else:
            mi_values = [mi_func(pair) for pair in channel_pairs]
        
        # æ„å»ºå¯¹ç§°çŸ©é˜µ
        mi_matrix = np.zeros((num_channels, num_channels))
        for (i, j), mi_value in zip(channel_pairs, mi_values):
            mi_matrix[i, j] = mi_value
            mi_matrix[j, i] = mi_value
        
        return mi_matrix
    
    def _compute_mi_pair(self, channel_pair, data):
        """è®¡ç®—å•ä¸ªé€šé“å¯¹çš„äº’ä¿¡æ¯ï¼ˆç”¨äºå¹¶è¡Œè®¡ç®—ï¼‰"""
        i, j = channel_pair
        return self.fast_mutual_information(
            data[:, i], data[:, j], method=self.mi_method
        )
    
    def apply_bandpass_filter(self, data, band, fs):
        """åº”ç”¨å¸¦é€šæ»¤æ³¢å™¨"""
        fmin, fmax = band
        nyquist = fs / 2
        low = fmin / nyquist
        high = min(fmax / nyquist, 0.99)
        
        b, a = butter(4, [low, high], btype='band')
        
        filtered_data = np.zeros_like(data)
        for ch in range(data.shape[1]):
            filtered_data[:, ch] = filtfilt(b, a, data[:, ch])
            
        return filtered_data
    
    def analyze_single_trial_fast(self, trial_idx):
        """å¿«é€Ÿåˆ†æå•ä¸ªtrialçš„äº’ä¿¡æ¯"""
        trial_data = self.trials[trial_idx]
        
        # å­˜å‚¨å„é¢‘æ®µçš„äº’ä¿¡æ¯çŸ©é˜µ
        band_mi_matrices = {}
        
        for band_name, band_range in self.bands.items():
            # åº”ç”¨å¸¦é€šæ»¤æ³¢
            filtered_data = self.apply_bandpass_filter(trial_data, band_range, self.fs)
            
            # é€‰æ‹©è®¡ç®—æ–¹æ³•
            if self.use_parallel and self.n_jobs > 1:
                mi_matrix = self.calculate_parallel_mi_matrix(filtered_data)
            else:
                mi_matrix = self.calculate_fast_mi_matrix(filtered_data)
            
            band_mi_matrices[band_name] = mi_matrix
        
        return band_mi_matrices
    
    def load_and_preprocess_data(self):
        """åŠ è½½å¹¶é¢„å¤„ç†EEGæ•°æ®"""
        if self.verbose:
            print("===== åŠ è½½æ•°æ® =====")
        trials, fs, ch_names, ch_pos, trial_labels, regions = load_eeg_data(self.subject_id)
        
        self.trials = trials
        self.fs = fs
        self.ch_names = ch_names
        self.ch_pos = ch_pos
        self.trial_labels = trial_labels
        self.regions = regions
        
        num_trials, num_timepoints, num_channels = trials.shape
        if self.verbose:
            print(f"æ•°æ®å½¢çŠ¶: {trials.shape}")
            print(f"è®¡ç®—å¤æ‚åº¦: {num_channels*(num_channels-1)//2} é€šé“å¯¹ Ã— 3 é¢‘æ®µ Ã— {num_trials} trials")
            print(f"ä½¿ç”¨æ–¹æ³•: {self.mi_method}")
            print(f"å¹¶è¡Œè®¡ç®—: {'æ˜¯' if self.use_parallel else 'å¦'} ({self.n_jobs} cores)")
        
        return trials
    
    def calculate_density_labels(self):
        """è®¡ç®—å¯†åº¦æ ‡ç­¾ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼Œç®€åŒ–è¾“å‡ºï¼‰"""
        if self.verbose:
            print("===== è®¡ç®—å¯†åº¦æ ‡ç­¾ =====")
        
        # æ•°æ®é¢„å¤„ç†ï¼šå±•å¹³
        num_trials, num_timepoints, num_channels = self.trials.shape
        flattened_trials = self.trials.reshape(num_trials, -1)
        
        # PCAé™ç»´
        if self.use_incremental_pca:
            pca = IncrementalPCA(n_components=self.pca_components, batch_size=self.pca_batch_size)
            n_samples = flattened_trials.shape[0]
            for i in range(0, n_samples, self.pca_batch_size):
                batch = flattened_trials[i:i + self.pca_batch_size]
                pca.partial_fit(batch)
            pca_results = pca.transform(flattened_trials)
        else:
            pca = PCA(n_components=self.pca_components, random_state=self.random_state)
            pca_results = pca.fit_transform(flattened_trials)
        
        # K-meansèšç±»
        kmeans = KMeans(n_clusters=self.kmeans_clusters, random_state=self.random_state)
        cluster_labels = kmeans.fit_predict(pca_results)
        
        # è®¡ç®—KNNå¯†åº¦
        nn = NearestNeighbors(n_neighbors=self.n_neighbors)
        nn.fit(pca_results)
        distances, _ = nn.kneighbors(pca_results)
        density = np.mean(distances, axis=1)
        
        # æŒ‰ç±»åˆ«åˆ’åˆ†å¯†åº¦é˜ˆå€¼
        clusters = np.unique(cluster_labels)
        density_labels = [''] * num_trials
        
        for cluster in clusters:
            cluster_mask = cluster_labels == cluster
            cluster_density = density[cluster_mask]
            threshold = np.percentile(cluster_density, self.density_percentile)
            
            high_density_mask = cluster_mask & (density <= threshold)
            low_density_mask = cluster_mask & (density > threshold)
            
            for i in range(num_trials):
                if high_density_mask[i]:
                    density_labels[i] = 'high'
                elif low_density_mask[i]:
                    density_labels[i] = 'low'
        
        density_labels = np.array(density_labels, dtype='U10')
        self.density_labels = density_labels
        self.cluster_labels = cluster_labels
        
        if self.verbose:
            high_count = np.sum(density_labels == 'high')
            low_count = np.sum(density_labels == 'low')
            print(f"å¯†åº¦æ ‡ç­¾åˆ†å¸ƒ: High={high_count}, Low={low_count}")
        
        return density_labels
    
    def calculate_average_mi_and_rank_channels(self, band_mi_matrices):
        """è®¡ç®—å¹³å‡äº’ä¿¡æ¯å¹¶æ’åºé€šé“"""
        # è®¡ç®—ä¸‰ä¸ªé¢‘æ®µçš„å¹³å‡äº’ä¿¡æ¯çŸ©é˜µ
        alpha_mi = band_mi_matrices['alpha']
        beta_mi = band_mi_matrices['beta'] 
        gamma_mi = band_mi_matrices['gamma']
        
        avg_mi_matrix = (alpha_mi + beta_mi + gamma_mi) / 3
        
        # è®¡ç®—æ¯ä¸ªé€šé“çš„è¿æ¥å¼ºåº¦
        channel_connectivity = np.sum(avg_mi_matrix, axis=1)
        
        # æ’åºè·å–å‰4ä¸ªé€šé“
        top_channels_indices = np.argsort(channel_connectivity)[-4:][::-1]
        top_channels_scores = channel_connectivity[top_channels_indices]
        top_channels_names = [self.ch_names[i] for i in top_channels_indices]
        
        return avg_mi_matrix, top_channels_indices, top_channels_scores, top_channels_names
    
    def analyze_all_trials_fast(self):
        """å¿«é€Ÿåˆ†ææ‰€æœ‰trials"""
        if self.verbose:
            print("===== å¼€å§‹å¿«é€Ÿäº’ä¿¡æ¯åˆ†æ =====")
        
        if not hasattr(self, 'density_labels'):
            self.calculate_density_labels()
        
        num_trials = self.trials.shape[0]
        results = []
        
        start_time = time.time()
        
        for trial_idx in range(num_trials):
            # è¿›åº¦æ˜¾ç¤º
            if self.verbose and trial_idx % max(1, num_trials // 10) == 0:
                elapsed = time.time() - start_time
                estimated_total = elapsed * num_trials / (trial_idx + 1) if trial_idx > 0 else 0
                remaining = estimated_total - elapsed
                print(f"è¿›åº¦: {trial_idx+1}/{num_trials} ({100*trial_idx/num_trials:.0f}%) - "
                      f"ç”¨æ—¶: {elapsed:.1f}s, é¢„è®¡å‰©ä½™: {remaining:.1f}s")
            
            # åˆ†æå½“å‰trial
            band_mi_matrices = self.analyze_single_trial_fast(trial_idx)
            avg_mi_matrix, top_indices, top_scores, top_names = self.calculate_average_mi_and_rank_channels(band_mi_matrices)
            
            # è·å–trialä¿¡æ¯
            original_label = self.trial_labels[trial_idx]
            density_label = self.density_labels[trial_idx]
            cluster_label = self.cluster_labels[trial_idx]
            
            # ä¿å­˜ç»“æœ
            trial_result = {
                'trial_idx': trial_idx,
                'original_label': original_label,
                'density_label': density_label,
                'cluster_label': cluster_label,
                'top_4_channels': top_names,
                'top_4_indices': top_indices,
                'top_4_scores': top_scores,
                'avg_mi_matrix': avg_mi_matrix,
                'band_mi_matrices': band_mi_matrices
            }
            
            results.append(trial_result)
        
        total_time = time.time() - start_time
        if self.verbose:
            print(f"åˆ†æå®Œæˆ! æ€»ç”¨æ—¶: {total_time:.1f}ç§’ ({total_time/num_trials:.2f}ç§’/trial)")
        
        self.results = results
        return results
    
    def save_results_to_csv(self, output_path='fast_mutual_information_results.csv'):
        """ä¿å­˜ç»“æœåˆ°CSV"""
        if self.verbose:
            print("===== ä¿å­˜ç»“æœåˆ°CSV =====")
        
        data_rows = []
        for result in self.results:
            row = {
                'trial_idx': result['trial_idx'],
                'original_label': result['original_label'],
                'density_label': result['density_label'],
                'cluster_label': result['cluster_label'],
                'top_channel_1': result['top_4_channels'][0],
                'top_channel_1_score': result['top_4_scores'][0],
                'top_channel_2': result['top_4_channels'][1],
                'top_channel_2_score': result['top_4_scores'][1],
                'top_channel_3': result['top_4_channels'][2],
                'top_channel_3_score': result['top_4_scores'][2],
                'top_channel_4': result['top_4_channels'][3],
                'top_channel_4_score': result['top_4_scores'][3],
            }
            data_rows.append(row)
        
        df = pd.DataFrame(data_rows)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        if self.verbose:
            print(f"ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        
        return df
    
    def run_fast_analysis(self, max_trials=None):
        """è¿è¡Œå¿«é€Ÿåˆ†ææµç¨‹"""
        if self.verbose:
            print("===== å¼€å§‹é«˜æ€§èƒ½äº’ä¿¡æ¯åˆ†æ =====")
            print(f"ä¼˜åŒ–ç­–ç•¥: {self.mi_method} + {'å¹¶è¡Œè®¡ç®—' if self.use_parallel else 'ä¸²è¡Œè®¡ç®—'}")
        
        # 1. åŠ è½½æ•°æ®
        self.load_and_preprocess_data()
        
        # 2. è®¡ç®—å¯†åº¦æ ‡ç­¾
        self.calculate_density_labels()
        
        # 3. æˆªå–æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if max_trials is not None and max_trials < self.trials.shape[0]:
            if self.verbose:
                print(f"æµ‹è¯•æ¨¡å¼ï¼šåªåˆ†æå‰ {max_trials} ä¸ªtrials")
            self.trials = self.trials[:max_trials]
            self.trial_labels = self.trial_labels[:max_trials]
            self.density_labels = self.density_labels[:max_trials]
            self.cluster_labels = self.cluster_labels[:max_trials]
        
        # 4. å¿«é€Ÿåˆ†æ
        self.analyze_all_trials_fast()
        
        # 5. ä¿å­˜ç»“æœ
        suffix = f'_first{max_trials}' if max_trials is not None else ''
        output_csv = f'fast_mutual_information_results_{self.subject_id}{suffix}.csv'
        df = self.save_results_to_csv(output_csv)
        
        if self.verbose:
            print("===== é«˜æ€§èƒ½åˆ†æå®Œæˆ =====")
        
        return self.results, df

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    quick_test = '--quick' in sys.argv or '-q' in sys.argv
    silent_mode = '--silent' in sys.argv or '-s' in sys.argv
    use_exact_mi = '--exact' in sys.argv
    disable_parallel = '--no-parallel' in sys.argv
    
    max_trials = 5 if quick_test else None
    
    # æ£€æŸ¥è‡ªå®šä¹‰trialsæ•°é‡
    for arg in sys.argv:
        if arg.startswith('--trials='):
            try:
                max_trials = int(arg.split('=')[1])
                quick_test = True
            except ValueError:
                if not silent_mode:
                    print("âš ï¸ æ— æ•ˆçš„trialså‚æ•°")
    
    # é€‰æ‹©äº’ä¿¡æ¯è®¡ç®—æ–¹æ³•
    if use_exact_mi:
        mi_method = 'mi_exact'
        if not silent_mode:
            print("ä½¿ç”¨ç²¾ç¡®äº’ä¿¡æ¯è®¡ç®—ï¼ˆè¾ƒæ…¢ä½†æœ€å‡†ç¡®ï¼‰")
    else:
        mi_method = 'correlation'
        if not silent_mode:
            print("ä½¿ç”¨ç›¸å…³ç³»æ•°è¿‘ä¼¼äº’ä¿¡æ¯ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
    
    # åˆ›å»ºé«˜æ€§èƒ½åˆ†æå™¨
    analyzer = FastMutualInformationAnalyzer(
        subject_id='aw',
        random_state=42,
        use_incremental_pca=True,
        pca_batch_size=50,
        verbose=not silent_mode,
        use_parallel=not disable_parallel,
        mi_method=mi_method,
        max_samples_per_trial=500  # å‡å°‘é‡‡æ ·ç‚¹ä»¥è¿›ä¸€æ­¥åŠ é€Ÿ
    )
    
    # æ˜¾ç¤ºæ¨¡å¼ä¿¡æ¯
    if not silent_mode:
        print("å¼€å§‹é«˜æ€§èƒ½åˆ†æ...")
        if quick_test:
            print(f"ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼š{max_trials} trials")
        else:
            print("ğŸ“Š å®Œæ•´åˆ†ææ¨¡å¼")
        print(f"æ–¹æ³•: {mi_method}")
        print(f"å¹¶è¡Œ: {'æ˜¯' if not disable_parallel else 'å¦'}")
        print("å‘½ä»¤è¡Œé€‰é¡¹:")
        print("  --quick: å¿«é€Ÿæµ‹è¯•")
        print("  --silent: é™é»˜æ¨¡å¼")
        print("  --exact: ä½¿ç”¨ç²¾ç¡®MIè®¡ç®—")
        print("  --no-parallel: ç¦ç”¨å¹¶è¡Œè®¡ç®—")
        print("  --trials=N: è‡ªå®šä¹‰trialsæ•°é‡")
    
    # è¿è¡Œåˆ†æ
    start_time = time.time()
    results, df = analyzer.run_fast_analysis(max_trials=max_trials)
    total_time = time.time() - start_time
    
    # æ˜¾ç¤ºç»“æœ
    if not silent_mode:
        print(f"\n===== æ€§èƒ½ç»Ÿè®¡ =====")
        print(f"æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print(f"å¹³å‡æ¯trial: {total_time/len(results):.2f}ç§’")
        print(f"å¤„ç†çš„trials: {len(results)}")
        
        print(f"\n===== æ ·ä¾‹ç»“æœ =====")
        for i in range(min(3, len(results))):
            result = results[i]
            print(f"Trial {result['trial_idx']}:")
            print(f"  åŸå§‹æ ‡ç­¾: {result['original_label']}")
            print(f"  å¯†åº¦æ ‡ç­¾: {result['density_label']}")
            print(f"  å‰4é€šé“: {result['top_4_channels']}")
            print()
    else:
        print(f"å®Œæˆ: {len(results)} trials, {total_time:.1f}s")

if __name__ == '__main__':
    main()